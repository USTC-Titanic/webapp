<!DOCTYPE html>
<html>
<head>
	<title>机器学习开发日志</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="/static/blog/post/post_template.css">
</head>

<body>
	<main class="container my_padding">
		<article class="markdown-body entry-content p-3 p-md-6">

<h1>机器学习实验笔记</h1>
<p>2019-04-22</p>
<h2>实验1 --- 基于 RNN 的 MNIST 手写字符识别实验</h2>
<ul>
<li>
<p>工作流</p>
<p>预处理(转化为灰度图) --- 卷积 --- 池化 --- 卷积 --- 池化 --- 全连接层 --- softmax --- 输出</p>
</li>
<li>
<p>简述卷积神经网络要素：卷积核、滤波器、池化、特征图</p>
</li>
<li>
<p>卷积</p>
<p>利用卷积操作可以从图像中提取特征</p>
<p>另外，卷积神经网络CNN，利用到了图像的局部相关性，这样可以减少全连接，减少需要训练的参数</p>
<p>卷积核相当于一个filter, 卷积核的大小一般采用 3x3 或 5x5</p>
<p>卷积操作, 相当于把卷积核作为一个 mask, 在像素矩阵上进行滑动, 然后进行加权求和作为特征值, 结果保存为新矩阵的对应像素点, 最后得到的新矩阵就是特征图</p>
<p>不同的卷积核, 可以提取图片的不同特征, 可以提升图片分类效果</p>
</li>
<li>
<p>池化</p>
<p>池化也是一种提取特征的方式, 池化操作的过程和卷积很类似, 但是池化层还可以起到降维的作用。根据参考资料, 这样做的效果之一是增加特征的鲁棒性，减小过拟合</p>
<p>池化分为平均值池化和最大值池化, 平均池化就是取这个区域的平均值作为特征值, 最大池化则是取最大值作为特征值。</p>
<p>池化层一般紧跟在卷积层后面。</p>
</li>
<li>
<p>padding</p>
<p>same padding , 如果滑动窗口在经过某个 stride 后超出了图像范围, 则需要在外面补 0 以继续滑动提取特征值。</p>
<p>valid padding , 超出范围的就不要了。</p>
</li>
<li>
<p>dropout, 随机丢弃, 防止过拟合, 同时加快训练速度</p>
</li>
</ul>
<h2>实验2 --- 基于 RNN 的注册码图像识别实验</h2>
<ul>
<li>
<p>工作流</p>
<p>预处理(转化为灰度图) --- 卷积 --- 池化 --- 卷积 --- 池化 --- 全连接层 --- softmax --- 输出</p>
<p>总体流程与实验1相同, 不过待识别数字从 1 个变成了 4 个(一起识别), 计算量更大</p>
</li>
</ul>
<h2>实验3 --- 基于 LSTM 的图像识别实验</h2>
<ul>
<li>
<p>工作流</p>
<p>预处理(转化为灰度图, 60x160) --- 划分为 160 列 --- LSTM --- 全连接层 --- softmax --- 输出</p>
</li>
<li>
<p>RNN</p>
<p>Recurrent neural network, 循环神经网络, 在语音识别、自然语言处理、机器翻译、图像描述等领域有广泛应用。</p>
<p>在处理语音的时候，由于上下文的相关性，需要把一段时间内的语音连起来进行分析，传统的神经网络做不到这一点。也就是说，与时间序列相关的分析和预测通常要用到RNN</p>
<p>即当前的预测值考虑到了之前的运行结果。</p>
</li>
<li>
<p>即使只有一层的RNN模型，仍可能出现梯度消失和梯度爆炸，为什么？</p>
<p>一层RNN模型里面有很多个单元，相当于有很多层的神经元，而不是只有一个神经元。</p>
<p>RNN在处理长期依赖（时间序列上距离较远的节点）时，距离较远的节点之间的联系时会涉及雅可比矩阵的多次相乘，这会带来梯度消失（经常发生）或者梯度爆炸（较少发生）的问题。不过问题的产生也和激活函数的选择有关，假设选择 y = x 作为激活函数就不会产生梯度消失的问题，当然实际应用中不会这样选择激活函数。</p>
<p>一般选择 ReLU</p>
</li>
<li>
<p>LSTM与一般的RNN相比，优势在哪？</p>
<p>LSTM, Long short-term memory, 长短时记忆网络, 是一种特殊结构的 RNN, 能够解决普通 RNN 不能解决的长期依赖问题。</p>
<p>普通 RNN 会记住久远的东西, 有用的没用的都记住了, 并且不会忘记, 这样会导致这个网络没有选择性。更合理的做法是，记住重要的，把不重要的忘记了。LSTM就是根据这种思想设计的。</p>
<p>LSTM包含了三个门, Input Gate, Output Gate, Forget Gate. 这三个门是用来控制信号的, 而不是信号直接通过这几个门进出。</p>
<p>输入信号从上图的最下面输进来, 然后 Input Gate 与输入信号进行相乘, 传给中间的 Cell. 也就是说, 如果这个输入的信号是重要的, 那么 Input Gate 就会让它进来, 如果没什么用, 那么 Input Gate 就不让它进来。Forget Gate 用于衰减信号,Output Gate 用于控制输出比例.</p>
<p>通过这三个门, LSTM 可以选出重要的信息, 帮助进行信号过滤。</p>
</li>
<li>
<p>GRU 是 LSTM 的一个变体</p>
<ul>
<li>
<p>对 memory 的控制</p>
<p>LSTM： 用output gate 控制，传输给下一个unit</p>
<p>GRU：直接传递给下一个unit，不做任何控制</p>
</li>
</ul>
</li>
</ul>

		</article>
	</main>
</body>

<section class="row justify-content-end">
	<div class="col-1 text-right">
		<button type="button" id="go-to-top" class="btn btn-sm btn-outline-primary" onclick="goToTop()" style="display: none; position: fixed; bottom: 80px; right: 16px;">↑</button>
	</div>
</section>

<script type="text/javascript">
// When the user scrolls down 20px from the top of the document, show the button
window.onscroll = function(){
	if (document.body.scrollTop > 100 || document.documentElement.scrollTop > 100) {
		document.getElementById("go-to-top").style.display = "block";
	} else {
		document.getElementById("go-to-top").style.display = "none";
	}
};

// https://www.w3schools.com/tags/ev_onclick.asp
// http://www.w3school.com.cn/jsref/met_win_setinterval.asp
function goToTop(){
	let t = setInterval( function(){
		if( document.documentElement.scrollTop <= 0 ){
			clearInterval(t);
		}else{
			document.documentElement.scrollTop -= 40;
		}
	}, 20);
};
</script>

</html>